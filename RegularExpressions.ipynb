{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/howto/regex.html\n",
    "\n",
    "# \"Regular expressions (called REs, or regexes, or regex patterns) are essentially a tiny, highly specialized programming \n",
    "# language embedded inside Python and made available through the re module. Using this little language, you specify the \n",
    "# rules for the set of possible strings that you want to match; this set might contain English sentences, or e-mail addresses, \n",
    "# or TeX commands, or anything you like. You can then ask questions such as “Does this string match the pattern?”, or \n",
    "# “Is there a match for the pattern anywhere in this string?”. You can also use REs to modify a string or to split it apart in \n",
    "# various ways.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: \n",
    "#    - alphanumeric here implies 0-9, a-z, A-Z, or _\n",
    "#    - a word is defined as a sequence of alphanumeric characters\n",
    "\n",
    "# metacharacters\n",
    "#    [ ]      matches character class specified within the square brackers\n",
    "#             - and ^ have special meaning within character class\n",
    "#             $ does not have special meaning within character class\n",
    "#     -      when used inside a characted class set, implies range of characters\n",
    "#    ^      when used as first character inside a character class set, implies match of complementing character class set\n",
    "#    \\       is used to either escape a metacharacter of its special meaning, or to signify a special squence\n",
    "#    .        matches anything except a newline character\n",
    "#    *       previous character is matched 0 or more times\n",
    "#    +      previous character is matched 1 or more times\n",
    "#    ?       previous characer is mathced 0 or 1 times\n",
    "#    { }     {m,n} means there must be at least m repetitions, and at most n\n",
    "#           {0,} is the same as *, {1,} is equivalent to +, and {0,1} is the same as ?\n",
    "#    ^     when NOT used as first character inside a character class set, matches at the begining of a line\n",
    "#    \\A    matches only at the start of a string (equivalent to ^ in non-MULTILINE mode)\n",
    "#    $     matches at the end of a line\n",
    "#    \\Z    matches only at the end of a string (equivalent to $ in non-MULTILINE mode)\n",
    "#    \\b    matches only at the begining or end of a word (that is, at a word boundary)\n",
    "#    \\B    matches only when not at the begining or end of a word (that is, not at a word boundary)\n",
    "#    |      matches either/or expression on either side of | opeartor\n",
    "#    ( )    used to group together the expressions contained inside;\n",
    "#           you can then repeat the contents of a group with a repeating qualifier, such as *, +, ?, or {m,n}\n",
    "\n",
    "# special squences (all sequencces can be included in a character set)\n",
    "#    \\d    matches any digit character; equivalent to [0-9]\n",
    "#    \\D    matches any non-digit character; equivalent to [^0-9]\n",
    "#    \\s     matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] => space, tab, newline, carriage return, form feed, vertical tab\n",
    "#    \\S     matches any non-whitespace character; equivalent to [^\\t\\n\\r\\f\\v] \n",
    "#    \\w    matches any alphanumeric character; equivalent to [0-9a-zA-Z_]\n",
    "#    \\W    matches any non-alphanumeric character; equivalent to [^0-9a-zA-Z_]\n",
    "\n",
    "# Raw Strings\n",
    "# Regular expressions use the backslash character ('\\') to indicate special forms or to allow \n",
    "#    special characters to be used without invoking their special meaning. \n",
    "# This conflicts with Python’s usage of the same character for the same purpose in string literals.\n",
    "# The solution is to use Python’s raw string notation for regular expressions.\n",
    "# This is done by preceeding the regular expression pattern by r\"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expressions are compiled into pattern objects:\n",
    "#    import re\n",
    "#    regex = re.compile(pattern, options)\n",
    "#        - pattern: created using metacharacters and special squences\n",
    "#        - options: can be re.IGNORECASE, re.VERBOSE, etc\n",
    "\n",
    "# Once a pattern object is created, you can use one of several methods on it to create a match object\n",
    "# match(): determines if the pattern matches at the begining of the string\n",
    "# search(): determines if the pattern matches at any location of the string\n",
    "# findall(): find all substrings where pattern matches, and return them as a list\n",
    "# finditer(): find all substrings where pattern matches, and return them as an iterator\n",
    "\n",
    "# Once a match object is created,  you can query the match object for information about the matching string\n",
    "# group(): returns string matched by the pattern\n",
    "# start(): return starting position of the match\n",
    "# end(): return ending position of the match\n",
    "# span(): return a tuple containing (start, end) position of the match\n",
    "\n",
    "# Once a pattern object is created, you can also use the following methods to modify strings\n",
    "# split(string[, maxsplit=0]): \n",
    "#               split the string into a list, splitting wherever the pattern matches \n",
    "#               if maxsplit is non-zero, at most maxsplit splits are performed (otherwise all splits are done)\n",
    "# sub(replacement, string[, count=0]): \n",
    "#               find all substrings where the pattern matches, and replace them with a different string\n",
    "#               if count is non-zero, at most count replacements are performed (otherwise all replacements are done)\n",
    "# subn(): same as sub, but returns new string and number of replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "Hey# Are we still on for lunch tod#y #t ###m?\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# first create an RE pattern object of all characters you'd like to match;\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[a!1]\")\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "H##! A## ## ##### ## ### ##### ##### ## 11##?\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# create an RE pattern object of all characters from a-z;\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[a-z]\")\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "###! ### ## ##### ## ### ##### ##### ## 11##?\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# create an RE pattern object of all characters from a-zA-Z;\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[a-zA-Z]\")\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "###! ### ## ##### ## ### ##### ##### ## 11##?\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# create an RE pattern object of all characters from a-z and make match case-insensitive (re.IGNORECASE)\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[a-z]\", re.IGNORECASE)\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "Hey! Are we still on for lunch today at ##am?\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# create an RE pattern object of all digits 0-9;\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[\\d]\")\n",
    "#regex = re.compile(r\"[0-9]\")\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "Hey##Are#we#still#on#for#lunch#today#at###am#\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# create an RE pattern object of the complement of all characters from a-zA-Z (that is, any characted that is not a-zA-Z)\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[^a-zA-Z]\")\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "########################################11###\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# create an RE pattern object of the complement of all characters from 0-9 (that is, any characted that is not 0-9)\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[^\\d]\")\n",
    "#regex = re.compile(r\"^[0-9]\")\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "Hey!#Are#we#still#on#for#lunch#today#at#11am?\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "\n",
    "# create an RE pattern object of whitespaces\n",
    "# then replace all matched characters with ''#''\n",
    "regex = re.compile(r\"[\\s]\")\n",
    "newstr = regex.sub('#', oldstr)\n",
    "print (oldstr)\n",
    "print (newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why Lisa, why, WHY\n",
      "# Lisa, #, #\n",
      "# Lisa, why, WHY\n",
      "Why Lisa, why, #\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"Why Lisa, why, WHY\"\n",
    "print (oldstr)\n",
    "\n",
    "# create an RE pattern object of  (case-insensitive) \"why\" anywhere in the string\n",
    "# then replace all matches with ''#''\n",
    "regex1 = re.compile(r\"why\", re.IGNORECASE)\n",
    "newstr1 = regex1.sub('#', oldstr)\n",
    "print (newstr1)\n",
    "\n",
    "# create an RE pattern object of (case-insensitive) \"why\" at the begining of the string\n",
    "# then replace all matches with ''#''\n",
    "regex2 = re.compile(r\"^why\", re.IGNORECASE)\n",
    "newstr2 = regex2.sub('#', oldstr)\n",
    "print (newstr2)\n",
    "\n",
    "# create an RE pattern object of (case-insensitive) \"why\" at the end of the string\n",
    "# then replace all matches with ''#''\n",
    "regex3 = re.compile(r\"why$\", re.IGNORECASE)\n",
    "newstr3 = regex3.sub('#', oldstr)\n",
    "print (newstr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cat will catch-up with you in muscat\n",
      "the # will #ch-up with you in mus#\n",
      "the # will catch-up with you in muscat\n",
      "the # will #ch-up with you in muscat\n",
      "the # will catch-up with you in mus#\n"
     ]
    }
   ],
   "source": [
    "oldstr = \"the cat will catch-up with you in muscat\"\n",
    "print (oldstr)\n",
    "\n",
    "# first create an RE pattern object of \"cat\"\n",
    "# then replace all matches with ''#''\n",
    "regex1 = re.compile(r\"cat\")\n",
    "newstr1 = regex1.sub('#', oldstr)\n",
    "print (newstr1)\n",
    "\n",
    "# first create an RE pattern object of \"cat\" at a word boundary at begining as well as end\n",
    "# then replace all matches with ''#''\n",
    "regex2 = re.compile(r\"\\bcat\\b\")\n",
    "newstr2 = regex2.sub('#', oldstr)\n",
    "print (newstr2)\n",
    "\n",
    "# first create an RE pattern object of \"cat\" at a word boundary at the begining \n",
    "# then replace all matches with ''#''\n",
    "regex3 = re.compile(r\"\\bcat\")\n",
    "newstr3 = regex3.sub('#', oldstr)\n",
    "print (newstr3)\n",
    "\n",
    "# first create an RE pattern object of \"cat\" at a word boundary at the end \n",
    "# then replace all matches with ''#''\n",
    "regex4 = re.compile(r\"cat\\b\")\n",
    "newstr4 = regex4.sub('#', oldstr)\n",
    "print (newstr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two files are foo1.bar and foo2.bar. There are no other files.\n",
      "['foo1.bar', 'foo2.bar']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: \n",
    "#    - find file names of the form base.extension  \n",
    "#    - and print the file names\n",
    "\n",
    "fnamestr = \"The two files are foo1.bar and foo2.bar. There are no other files.\"\n",
    "print (fnamestr)\n",
    "\n",
    "regex = re.compile(r\"\\b\\w+[.]\\w+\\b\")\n",
    "fnames = regex.findall(fnamestr)\n",
    "print (fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! Are we still on for lunch today at 11am?\n",
      "Hey Are we still on for lunch today at 11am\n",
      "Hey Are we still on for lunch today at am\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2:\n",
    "#     - find punctuations and digits\n",
    "#     - replace with empty\n",
    "\n",
    "oldstr = \"Hey! Are we still on for lunch today at 11am?\"\n",
    "print (oldstr)\n",
    "\n",
    "regex1 = re.compile(r\"[%s]\" % string.punctuation)\n",
    "newstr1 = regex1.sub('',oldstr)\n",
    "print (newstr1)\n",
    "\n",
    "regex1 = re.compile(r\"[%s%s]\" % (string.punctuation,string.digits))\n",
    "newstr1 = regex1.sub('',oldstr)\n",
    "print (newstr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "- https://spacy.io/\n",
    "- https://spacy.io/usage\n",
    "- https://spacy.io/models/en\n",
    "- https://spacy.io/api/doc\n",
    "- https://spacy.io/api/token\n",
    "- https://spacy.io/usage/processing-pipelines\n",
    "- https://spacy.io/usage/spacy-101\n",
    "\n",
    "\n",
    "\n",
    " - **spaCy** is a free, open-source library for advanced industrial-strength Natural Language Processing (NLP) in Python.\n",
    "\n",
    "- When you call spaCy on a text, spaCy first tokenizes the text (i.e. segments it into words, punctuation and so on) to produce a Doc object. \n",
    "   spaCy uses rules specific to each language for tokenization.\n",
    "\n",
    " - The Doc object is then processed in several different steps (also referred to as the processing pipeline). \n",
    "   The pipeline used by the default models consists of a (pos) tagger, a (dependency) parser and a (named) entity recognizer (ner). \n",
    "   spaCy uses statistical models to predict pos, syntatctic dependencies, and named entities.\n",
    "   Each pipeline component returns the processed Doc, which is then passed on to the next component.\n",
    "   You can pick and choose the stages you want spaCy to load.\n",
    "\n",
    "- Here is a list of features and capabilities of spaCy: \n",
    "  https://spacy.io/usage/spacy-101#features\n",
    "\n",
    "### installation\n",
    "\n",
    "#### https://spacy.io/usage\n",
    "- `pip install spacy`\n",
    "\n",
    "#### https://spacy.io/models/en\n",
    "you can download these general-purpose pretrained models to predict \n",
    "pos tags (tagger), named entities (ner), and syntactic dependencies (parser).\n",
    "    note: n_core_web_sm does not include **word-vectors**, but en_core_web_md and en_core_web_lg do.\n",
    "> `python -m spacy download en_core_web_sm` <br>\n",
    "> `python -m spacy download en_core_web_md` <br>\n",
    "> `python -m spacy download en_core_web_lg`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once you’ve downloaded and installed a model, you can load it via spacy.load(). \n",
    "# spacy.load() returns a Language object containing all components and data needed to process text. \\\n",
    "\n",
    "# the Language object is typically called nlp. \n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the nlp object on a string of text will return a processed Doc object. the Doc object is typically called doc.\n",
    "# even though a Doc object is processed (for isntance, split into individual words and annotated),\n",
    "# it still holds all information of the original text.\n",
    "# once the doc object has been created, we can  use it to access the various spaCy features.\n",
    "doc = nlp(\"Hi Emma Watson! How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Emma Watson!\n",
      "How are you?\n"
     ]
    }
   ],
   "source": [
    "# for instance, you can iterate over individual sentences in the document.\n",
    "for s in doc.sents:\n",
    "    print (s.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson\n",
      "PERSON\n",
      "People, including fictional\n"
     ]
    }
   ],
   "source": [
    "# you can iterate over the named entities in the document (from ner)\n",
    "# a named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title.\n",
    "for e in doc.ents:\n",
    "    print (e.text)\n",
    "    print (e.label_)\n",
    "    print (spacy.explain(e.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi Emma \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Watson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "! How are you?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can visualize the named entities \n",
    "spacy.displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"77981236cd0a47158dade01547e2e9f9-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Emma</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Watson!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">How</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">you?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77981236cd0a47158dade01547e2e9f9-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77981236cd0a47158dade01547e2e9f9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77981236cd0a47158dade01547e2e9f9-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77981236cd0a47158dade01547e2e9f9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77981236cd0a47158dade01547e2e9f9-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77981236cd0a47158dade01547e2e9f9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77981236cd0a47158dade01547e2e9f9-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77981236cd0a47158dade01547e2e9f9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can also visualize the dependencies (from parser)\n",
    "spacy.displacy.render(doc, style=\"dep\", jupyter= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Emma Watson\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "# you can iterate over the base noun chunks in the document.\n",
    "# noun chunks are “base noun phrases”  - a noun plus the words describing the noun.\n",
    "# for instance, “the lavish green grass” or “the world’s largest tech fund”.\n",
    "for c in doc.noun_chunks:\n",
    "    print (c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Hi Hi  None hi INTJ interjection UH interjection compound False False False False True True False False False True False False False\n",
      "1 Emma Emma  None Emma PROPN proper noun NNP noun, proper singular compound False False False False True True False False False True False False False\n",
      "2 Watson Watson PERSON People, including fictional Watson PROPN proper noun NNP noun, proper singular ROOT False False False False True True False False False True False False False\n",
      "3 ! !  None ! PUNCT punctuation . punctuation mark, sentence closer punct False False False False False True False False False False True False False\n",
      "4 How How  None how ADV adverb WRB wh-adverb advmod False False False True True True False False False True False False False\n",
      "5 are are  None be AUX auxiliary VBP verb, non-3rd person singular present ROOT False False False True True True False True False False False False False\n",
      "6 you you  None -PRON- PRON pronoun PRP pronoun, personal nsubj False False False True True True False True False False False False False\n",
      "7 ? ?  None ? PUNCT punctuation . punctuation mark, sentence closer punct False False False False False True False False False False True False False\n"
     ]
    }
   ],
   "source": [
    "# you can iterate over the linguisitic annotations associated with tokens in the document (from tagger)\n",
    "# https://spacy.io/api/annotation\n",
    "# https://spacy.io/api/token#attributes\n",
    "doc = nlp(\"Hi Emma Watson! How are you?\")\n",
    "for token in doc:\n",
    "    print (token.i,                 # index of the token within the parent document\n",
    "           token,\n",
    "           token.text,               # verbatim text\n",
    "           token.ent_type_,     # named entity type\n",
    "           spacy.explain(token.ent_type_),\n",
    "           token.lemma_,        # base form of the token, with no inflectional suffixes\n",
    "           token.pos_,             # coarse-grained part-of-speech\n",
    "            spacy.explain(token.pos_),\n",
    "           token.tag_,             # fine-grained part-of-speech\n",
    "            spacy.explain(token.tag_),\n",
    "           token.dep_,            # syntactic dependency relation\n",
    "           token.like_url,        # does the token resemble a URL\n",
    "           token.like_num,     # does the token represent a number? e.g. “10.9”, “10”, “ten”, etc\n",
    "           token.like_email,    # does the token resemble an email address\n",
    "           token.is_stop,         # is the token part of a “stop list”\n",
    "          token.is_alpha,\n",
    "          token.is_ascii,\n",
    "          token.is_digit,\n",
    "          token.is_lower,\n",
    "          token.is_upper,\n",
    "          token.is_title,\n",
    "          token.is_punct,\n",
    "          token.is_space,\n",
    "          token.is_currency\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-abf7efea721c>:8: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  doc1.similarity(doc2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9100590601885606"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can make semantic similarity estimates based on word vectors.\n",
    "# the default estimate is cosine similarity, using an average of word vectors for the document.\n",
    "# it returns a scalar similarity score (higher is more similar).\n",
    "doc1 = nlp(\"I like oranges that are sweet.\")\n",
    "# print (doc1.vector) # doc vector is average of token vectors\n",
    "doc2 = nlp(\"I like apples that are sour.\")\n",
    "# print (doc2.vector) # doc vector is average of token vectors\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amy go class', 'matt have lunch']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processing large corpuses with nlp.pipe\n",
    "\n",
    "# let's say you had a very large corpus of text\n",
    "# illustrated with a very small corpus below :)\n",
    "data = [\"Amy is going to class now.\",\n",
    "          \"Matt is having lunch.\"]\n",
    "\n",
    "# first, you'll only want to apply the pipeline components you need:\n",
    "# getting predictions from the model that you don’t actually need adds up and becomes very inefficient at scale. \n",
    "# to prevent this, use the disable keyword argument to disable components you don’t need.\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# and second, you'll want to work on batches of texts.\n",
    "# this can be done with spaCy’s nlp.pipe method which takes an iterable of texts and yields processed Doc objects. \n",
    "# the batching is done internally.\n",
    "corpus = nlp.pipe(data)\n",
    "\n",
    "# now we can clean the corpus efficiently\n",
    "def custom_tokenizer(doc):\n",
    "    tokens = [token.lemma_.lower() \n",
    "                      for token in doc \n",
    "                          if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "clean_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise\n",
    "\n",
    "#### Question 1\n",
    "Lowercase the text.\n",
    "- `text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes, that is a duplicate catalog category. the catalog number is c1357-a.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Substitute the pattern `\"cat\"` with replacement `\"#\"` in the text.\n",
    "- make the substitution case sensitive,\n",
    "- and match the pattern wherever it occurs in the text\n",
    "  - `text = \"Yes, that is a duplicate Catalog category. The Catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is a dupli#e #alog #egory. The #alog number is C1357-A.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r\"cat\")\n",
    "newtext = regex.sub('#', text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Substitute the pattern \"cat\" with replacement \"#\" in the text\n",
    "- make the substitution case insensitive (re.IGNORECASE)\n",
    "- and match the pattern wherever it occurs in the text\n",
    "  - `text = \"Yes, that is a duplicate Catalog category. The Catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is a dupli#e #alog #egory. The #alog number is C1357-A.\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r\"cat\", re.IGNORECASE)\n",
    "newtext = regex.sub('#', text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Substitute the pattern \"cat\" with replacement \"#\" in the text\n",
    "- make the substitution case insensitive\n",
    "- only match if the pattern is at the beginning of a word boundary (\\b)\n",
    "  - `text = \"Yes, that is a duplicate Catalog category. The Catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is a duplicate #alog #egory. The #alog number is C1357-A.\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r\"\\bcat\", re.IGNORECASE)\n",
    "newtext = regex.sub('#', text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "Substitute the characters 'c', 'a', 't' with replacement \"#\" in the text\n",
    "- make the substitution case insensitive\n",
    "- hint: use character class r\"[cat]“\n",
    "  - `text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, #h## is # dupli###e ####log ###egory. #he ####log number is #1357-#.\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r\"[cat]\", re.IGNORECASE)\n",
    "newtext = regex.sub('#', text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "Substitute all alphabets with replacement \"#\" in the text\n",
    "- make the substitution case insensitive\n",
    "- hint: use character class with range [a-z]\n",
    "  - `text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###, #### ## # ######### ####### ########. ### ####### ###### ## #1357-#.\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r\"[a-z]\", re.IGNORECASE)\n",
    "newtext = regex.sub('#', text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Substitute all digits with replacement \"#\" in the text\n",
    "- hint: use character class with range [0-9], or special sequence \\d = [0-9]\n",
    "  - `text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is a duplicate catalog category. The catalog number is C####-A.\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r\"[0-9]\")\n",
    "newtext = regex.sub('#', text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "Substitute one or more white-space characters with replacement \" \" in the spacetext\n",
    "- hint: use special sequence \\s for whitespace characters, and metacharacter + for one-or-moretimes\n",
    "  - `spacetext = \"Yes, that is a duplicate catalog \\t category. The catalog number is C1357-A.\\n\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is a duplicate catalog category. The catalog number is C1357-A. \n"
     ]
    }
   ],
   "source": [
    "spacetext = \"Yes, that is a duplicate catalog \\t category. The catalog number is C1357-A.\\n\"\n",
    "\n",
    "regex = re.compile(r\"\\s+\")\n",
    "newtext = regex.sub(' ', spacetext)\n",
    "# print(spacetext)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9\n",
    "Substitute words that are two or more alphanumeric characters long\n",
    "with replacement \"#\"\n",
    "- use special sequence \\w for alphanumeric characters [0-9a-zA-Z_],\n",
    "- special sequence \\b for words boundaries,\n",
    "- and metacharacter + for one-or-more-times, or {2,} for two or more times\n",
    "  - `text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#, # # a # # #. # # # # #-A.\n"
     ]
    }
   ],
   "source": [
    "text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"\n",
    "\n",
    "regex = re.compile(r\"[\\w]{2,}\")\n",
    "newtext = regex.sub('#', text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10\n",
    "Find all words that are two or more characters long\n",
    "- hint: use regex.findall(text)\n",
    "  - `text = \"Yes, that is a duplicate catalog category. The catalog number is C1357-A.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes', 'that', 'is', 'duplicate', 'catalog', 'category', 'The', 'catalog', 'number', 'is', 'C1357']\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r\"\\b\\w{2,}\\b\")\n",
    "newtext = regex.findall(text)\n",
    "print(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11 (@20:00)\n",
    "Find all the urls in urltext\n",
    "- take care of http vs https\n",
    "- hint: use metacharacter ? for zero-or-one-times, metacharacter + for one-or-more-times, and \\S for non-whitespace characters\n",
    "  - `urltext = \"\"\"The url for sklearn documentation …\"\"\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
